{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 224, 224\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.pool1(F.relu(self.conv1(x)))\n",
    "        out = self.pool2(F.relu(self.conv2(out)))\n",
    "        out = self.pool3(F.relu(self.conv3(out)))\n",
    "        \n",
    "        out = self.flatten(out)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        \n",
    "        return torch.sigmoid(self.fc3(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, path, transformations=None):\n",
    "        self.train_data = ImageFolder(f'{path}/train', transform=transformations)\n",
    "        self.test_data = ImageFolder(f'{path}/test', transform=transformations)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_data) + len(self.test_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # return the features and target separated\n",
    "        return self.dataset[index, :-1], self.dataset[index, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, train, test, batch_size, shuffle=True):\n",
    "        self.train_data = train\n",
    "        self.test_data = test\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def load(self):\n",
    "        loaders = (torch.utils.data.DataLoader(self.train_data, batch_size=self.batch_size, shuffle=self.shuffle),\n",
    "                   torch.utils.data.DataLoader(self.test_data, batch_size=self.batch_size, shuffle=self.shuffle))\n",
    "        \n",
    "        return loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train, test, n_epochs, optimizer, loss_fn, print_plot=True):\n",
    "    train_accuracy = torch.zeros(n_epochs)\n",
    "    test_accuracy = torch.zeros(n_epochs)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for example, label in train:\n",
    "            example = example.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "\n",
    "            # return a list instead of a list of one element lists\n",
    "            label = label.unsqueeze(1)\n",
    "\n",
    "            # predict and compute loss\n",
    "            output = model(example.float())\n",
    "            loss = loss_fn(output, label.float())\n",
    "\n",
    "            optimizer.zero_grad() # zero gradient (make errors to 0)\n",
    "            loss.backward()\n",
    "            optimizer.step() # change weights\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for loader, accuracy in [(train, train_accuracy), (test, test_accuracy)]:\n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "                for examples, labels in loader:\n",
    "                    examples = examples.to(device=DEVICE)\n",
    "                    labels = labels.to(device=DEVICE).view(-1, 1)\n",
    "\n",
    "                    outputs = model(examples.float())\n",
    "                    predicted = torch.round(outputs)\n",
    "\n",
    "                    total += labels.shape[0]\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy[epoch] = correct / total\n",
    "        \n",
    "        # print the accuracy of every tenth epoch\n",
    "        if (epoch+1) % 10 ==0:\n",
    "            print(f'Epoch {epoch+1})', \n",
    "                  f'Train Accuracy: {train_accuracy[epoch]}',\n",
    "                  f'Test Accuracy: {test_accuracy[epoch]}') \n",
    "        \n",
    "    if print_plot:\n",
    "        epochs = range(n_epochs)\n",
    "\n",
    "        #Ploting both curves, train and val \n",
    "        plt.plot(epochs, train_accuracy, 'g', label='Training accuracy')\n",
    "        plt.plot(epochs, test_accuracy, 'b', label='Test accuracy')\n",
    "        plt.title('Training and Test loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "data = DataSet('./task_4_data', transformations)\n",
    "train_loader, test_loader = DataLoader(data.train_data, data.test_data, batch_size=32).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14300/1566414144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m training_loop(\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14300/4227932049.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(model, train, test, n_epochs, optimizer, loss_fn, print_plot)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# zero gradient (make errors to 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# change weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNN().to(DEVICE)\n",
    "n_epochs = 24\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "training_loop(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    n_epochs,\n",
    "    optimizer,\n",
    "    loss_fn\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f3b078249380ea762697f4f8f6aea77b3d6e43cbb1b18cbb73d8cde5aa597e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
